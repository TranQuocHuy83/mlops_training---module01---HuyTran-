{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFoTcHXeOBHnC6qfT7vYAN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranQuocHuy83/mlops_training---module01---HuyTran-/blob/main/03_tensor_manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Exercise 3: Tensor Manipulation\n",
        "PyTorch Fundamentals - Module 1\n",
        "\n",
        "This exercise covers:\n",
        "- Reshaping tensors\n",
        "- Indexing and slicing\n",
        "- Transposing and permuting\n",
        "- Squeezing and unsqueezing\n",
        "- Concatenating and splitting tensors\n",
        "\n",
        "PyTorch 2.0 Note: All manipulation operations are compatible with PyTorch 2.0.\n",
        "See the device management section for torch.set_default_device() (PyTorch 2.0+ feature).\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "In7KkNoCj38g",
        "outputId": "462126b5-065e-47db-91ec-53943ec0f9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x795bfdf29f30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================\n",
        "# Part 1: Reshaping\n",
        "# ============================================"
      ],
      "metadata": {
        "id": "gmr67XILkhtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Part 1: Reshaping Tensors\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a 1D tensor\n",
        "x = torch.arange(12)\n",
        "print(f\"Original tensor: {x}\")\n",
        "print(f\"Original shape: {x.shape}\")\n",
        "print(f\"Original shape: {x.ndim}\")"
      ],
      "metadata": {
        "id": "i7PXRVEUkmh3",
        "outputId": "44234047-0756-433c-d994-504b5a1a5b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Part 1: Reshaping Tensors\n",
            "============================================================\n",
            "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
            "Original shape: torch.Size([12])\n",
            "Original shape: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Reshape to 3x4\n",
        "reshaped = x.reshape(3, 4)\n",
        "print(f\"\\nReshaped to (3, 4):\\n{reshaped}\")\n",
        "print(f\"Original shape: {reshaped.shape}\")\n",
        "print(f\"Original shape: {reshaped.ndim}\")"
      ],
      "metadata": {
        "id": "SDqSkxqRln-V",
        "outputId": "bc077f21-0956-4c21-b16c-f5f6b2732390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reshaped to (3, 4):\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "Original shape: torch.Size([3, 4])\n",
            "Original shape: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Reshape to 2x6\n",
        "reshaped_2x6 = x.reshape(2, 6)\n",
        "print(f\"\\nReshaped to (2, 6):\\n{reshaped_2x6}\")\n",
        "print(f\"Original shape: {reshaped_2x6.shape}\")\n",
        "print(f\"Original shape: {reshaped_2x6.ndim}\")"
      ],
      "metadata": {
        "id": "abLvLjgfl7nz",
        "outputId": "14fbc9e6-c132-4473-e2f4-7d7667257cab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reshaped to (2, 6):\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n",
            "Original shape: torch.Size([2, 6])\n",
            "Original shape: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Flatten a 2D tensor\n",
        "flat1 = reshaped.flatten()\n",
        "print(f\"\\nFlattened: {flat1}\")"
      ],
      "metadata": {
        "id": "vt_-TARgmHh0",
        "outputId": "28ab333f-0699-4e7f-c919-3f3f2584e756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Flattened: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Flatten a 2D tensor\n",
        "flat2 = reshaped_2x6.flatten()\n",
        "print(f\"\\nFlattened: {flat2}\")"
      ],
      "metadata": {
        "id": "3oaPxximmMw0",
        "outputId": "23ba4b56-b2a9-4569-91e1-22782c849dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Flattened: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Reshape with view (only works on contiguous tensors)\n",
        "viewed = reshaped.view(-1)  # -1 means infer dimension\n",
        "print(f\"\\nViewed as 1D: {viewed}\")"
      ],
      "metadata": {
        "id": "gBt4Q7qwmiUw",
        "outputId": "f16864bc-6524-4aa6-c9b2-1988b1b9561c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Viewed as 1D: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = torch.arange(12)\n",
        "R = T.reshape(2, 2, 3)\n",
        "R_V = reshaped.view(-1)\n",
        "print(T)\n",
        "print(R)\n",
        "print(R_V)"
      ],
      "metadata": {
        "id": "hWTYq4Q0ozdu",
        "outputId": "0e97b149-bc36-4688-ba75-cba41e591f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================\n",
        "# Part 2: Squeeze and Unsqueeze\n",
        "# ============================================"
      ],
      "metadata": {
        "id": "58T49Eo4nPG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 2: Squeeze and Unsqueeze\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create tensor with singleton dimensions\n",
        "x = torch.randn(2, 1, 4, 1) #(batch, channel, height, width)\n",
        "print(f\"Original tensor:\\n{x}\")\n",
        "print(f\"Original dim: {x.dim}\")\n",
        "print(f\"Original shape: {x.shape}\")"
      ],
      "metadata": {
        "id": "CaHTEdYvp5EU",
        "outputId": "fee79965-eccc-49a0-b65d-3d2c38d92b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Part 2: Squeeze and Unsqueeze\n",
            "============================================================\n",
            "Original tensor:\n",
            "tensor([[[[ 1.3221],\n",
            "          [ 0.8172],\n",
            "          [-0.7658],\n",
            "          [-0.7506]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3525],\n",
            "          [ 0.6863],\n",
            "          [-0.3278],\n",
            "          [ 0.7950]]]])\n",
            "Original dim: <built-in method dim of Tensor object at 0x795be19c79d0>\n",
            "Original shape: torch.Size([2, 1, 4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Remove all singleton dimensions\n",
        "squeezed = x.squeeze()\n",
        "print(f\"\\nAfter squeeze:\\n{squeezed}\")\n",
        "print(f\"After squeeze: {squeezed.shape}\")"
      ],
      "metadata": {
        "id": "K2YW5tp3vaUc",
        "outputId": "9fbba6fe-2f59-4cc2-ab90-b9c79516e323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After squeeze:\n",
            "tensor([[ 1.3221,  0.8172, -0.7658, -0.7506],\n",
            "        [ 1.3525,  0.6863, -0.3278,  0.7950]])\n",
            "After squeeze: torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Remove specific singleton dimension\n",
        "squeezed_dim = x.squeeze(dim=1)\n",
        "print(f\"\\nAfter squeeze(dim=1): {squeezed_dim}\")\n",
        "print(f\"After squeeze(dim=1): {squeezed_dim.shape}\")"
      ],
      "metadata": {
        "id": "hpG_kEYlv6h_",
        "outputId": "82d8cb20-5d5e-4cac-87f7-f4873f66379a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After squeeze(dim=1): tensor([[[ 1.3221],\n",
            "         [ 0.8172],\n",
            "         [-0.7658],\n",
            "         [-0.7506]],\n",
            "\n",
            "        [[ 1.3525],\n",
            "         [ 0.6863],\n",
            "         [-0.3278],\n",
            "         [ 0.7950]]])\n",
            "After squeeze(dim=1): torch.Size([2, 4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U60sUP6rn9fb"
      },
      "outputs": [],
      "source": [
        "# TODO: Add dimension at position 0\n",
        "unsqueezed_0 = squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nAfter unsqueeze(dim=0): {unsqueezed_0.shape}\")\n",
        "\n",
        "# TODO: Add dimension at last position\n",
        "unsqueezed_last = squeezed.unsqueeze(dim=-1)\n",
        "print(f\"After unsqueeze(dim=-1): {unsqueezed_last.shape}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Part 3: Transpose and Permute\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 3: Transpose and Permute\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a 3D tensor\n",
        "x = torch.randn(2, 3, 4)\n",
        "print(f\"Original shape: {x.shape}\")\n",
        "\n",
        "# TODO: Transpose dimensions 0 and 1\n",
        "transposed = torch.transpose(x, 0, 1)\n",
        "print(f\"After transpose(0, 1): {transposed.shape}\")\n",
        "\n",
        "# TODO: Permute all dimensions\n",
        "permuted = x.permute(2, 0, 1)\n",
        "print(f\"After permute(2, 0, 1): {permuted.shape}\")\n",
        "\n",
        "# TODO: Matrix transpose for 2D tensor\n",
        "matrix = torch.randn(3, 4)\n",
        "print(f\"\\nMatrix shape: {matrix.shape}\")\n",
        "print(f\"Matrix.T shape: {matrix.T.shape}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Part 4: Indexing and Slicing\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 4: Indexing and Slicing\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a 2D tensor\n",
        "x = torch.arange(20).reshape(4, 5)\n",
        "print(f\"Tensor:\\n{x}\")\n",
        "\n",
        "# TODO: Get element at position (1, 2)\n",
        "element = x[1, 2]\n",
        "print(f\"\\nElement at [1, 2]: {element}\")\n",
        "\n",
        "# TODO: Get first row\n",
        "first_row = x[0, :]\n",
        "print(f\"\\nFirst row: {first_row}\")\n",
        "\n",
        "# TODO: Get last column\n",
        "last_col = x[:, -1]\n",
        "print(f\"Last column: {last_col}\")\n",
        "\n",
        "# TODO: Get submatrix (rows 1-2, cols 2-4)\n",
        "submatrix = x[1:3, 2:5]\n",
        "print(f\"\\nSubmatrix [1:3, 2:5]:\\n{submatrix}\")\n",
        "\n",
        "# TODO: Boolean indexing\n",
        "mask = x > 10\n",
        "values = x[mask]\n",
        "print(f\"\\nValues > 10: {values}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Part 5: Concatenating and Splitting\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 5: Concatenating and Splitting\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create tensors to concatenate\n",
        "x1 = torch.randn(2, 3)\n",
        "x2 = torch.randn(2, 3)\n",
        "x3 = torch.randn(2, 3)\n",
        "\n",
        "print(f\"x1 shape: {x1.shape}\")\n",
        "print(f\"x2 shape: {x2.shape}\")\n",
        "\n",
        "# TODO: Stack along new dimension (dim=0)\n",
        "stacked = torch.stack([x1, x2, x3], dim=0)\n",
        "print(f\"\\nStacked along dim=0: {stacked.shape}\")\n",
        "\n",
        "# TODO: Concatenate along existing dimension (dim=0)\n",
        "concat_dim0 = torch.cat([x1, x2, x3], dim=0)\n",
        "print(f\"Concatenated along dim=0: {concat_dim0.shape}\")\n",
        "\n",
        "# TODO: Split tensor into chunks\n",
        "x = torch.randn(6, 4)\n",
        "chunks = torch.chunk(x, chunks=3, dim=0)\n",
        "print(f\"\\nSplit into 3 chunks along dim=0:\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"  Chunk {i} shape: {chunk.shape}\")\n",
        "\n",
        "# TODO: Split at specific indices\n",
        "split_sections = torch.split(x, [2, 4], dim=0)\n",
        "print(f\"\\nSplit into sections of size [2, 4]:\")\n",
        "for i, section in enumerate(split_sections):\n",
        "    print(f\"  Section {i} shape: {section.shape}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Exercises\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercises\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Exercise 1: Given a tensor of shape (64, 1, 28, 28), remove the singleton dimension\n",
        "print(\"\\nExercise 1: Remove singleton dimension\")\n",
        "x = torch.randn(64, 1, 28, 28)\n",
        "# Your code here\n",
        "\n",
        "# Exercise 2: Add a batch dimension to a single image tensor of shape (3, 224, 224)\n",
        "print(\"\\nExercise 2: Add batch dimension\")\n",
        "image = torch.randn(3, 224, 224)\n",
        "# Your code here - should result in (1, 3, 224, 224)\n",
        "\n",
        "# Exercise 3: Convert HWC format to CHW format\n",
        "print(\"\\nExercise 3: HWC to CHW conversion\")\n",
        "hwc_image = torch.randn(224, 224, 3)\n",
        "# Your code here - should result in (3, 224, 224)\n",
        "\n",
        "# Exercise 4: Extract the diagonal elements from a square matrix\n",
        "print(\"\\nExercise 4: Extract diagonal\")\n",
        "matrix = torch.randn(5, 5)\n",
        "# Your code here\n",
        "\n",
        "# Exercise 5: Create a batch of 10 random images and stack them\n",
        "print(\"\\nExercise 5: Stack images into batch\")\n",
        "images = [torch.randn(3, 224, 224) for _ in range(10)]\n",
        "# Your code here - should result in (10, 3, 224, 224)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercise 3 Complete!\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ]
}